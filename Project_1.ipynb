{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rainshield/COMP551/blob/main/Project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8tZAOq-hF-n"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from google.colab import files    \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')  \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class reg_dat:\n",
        "    \n",
        "      \n",
        "       \n",
        "    '''\n",
        "    Regression data class. The class loads the data, calculates the statistical summaries, \n",
        "    prints, and saves them if needed. The esplit function splits the data into train-test\n",
        "    parts based on a given ratio. If 'normalize' method is raised, z-score normalized \n",
        "    versions of train and test set are created and stored in the class. \n",
        "    \n",
        "    pth: Path to the data location\n",
        "    '''\n",
        "    def __init__(self, pth):\n",
        "        self.dat     = pd.read_excel(pth)\n",
        "        self.n       = self.dat.shape[0]\n",
        "        self.x_train = None\n",
        "        self.y_train = None\n",
        "        self.x_test  = None     \n",
        "        self.y_test  = None\n",
        "             \n",
        "    def stat_sum(self, prnt, save): #Provide statistical summary of the data\n",
        "        stat_sum = pd.DataFrame(self.dat.describe())\n",
        "        cat_1 = (self.dat['X8'].value_counts()/self.n) * 100 #Categorical data\n",
        "        cat_2 = (self.dat['X6'].value_counts()/self.n) * 100\n",
        "        cat_3 = (self.dat['X4'].value_counts()/self.n) * 100\n",
        "        cat_4 = (self.dat['X5'].value_counts()/self.n) * 100\n",
        "        cat_5 = (self.dat['X7'].value_counts()/self.n) * 100\n",
        "        all_cat = pd.concat([cat_1, cat_2, cat_3, cat_4, cat_5], axis=1)\n",
        "        if prnt:\n",
        "            print(stat_sum)\n",
        "            print('Categorical data:')\n",
        "            print(all_cat)\n",
        "        if save: \n",
        "            stat_sum.to_excel('statistical_summary.xlsx')\n",
        "            all_cat.to_excel('categorical_statistical_summary.xlsx')\n",
        "           \n",
        "    def split(self, tst_ratio, outcm=9, rnd_stat=100):        \n",
        "        # Split into train test sets. Note that the outcomes are Y1 (8), Y2 (9)\n",
        "        if not( outcm == 9 or outcm ==8):\n",
        "            print('Warning! Your choosing an independent variable as outcome!')\n",
        "            \n",
        "        x_train, x_test, y_train, y_test = train_test_split(self.dat.iloc[:, 0:8],\n",
        "                                                               self.dat.iloc[:, outcm],\n",
        "                                                               test_size=tst_ratio,\n",
        "                                                               random_state=rnd_stat)\n",
        "        self.x_train = x_train.values\n",
        "        self.x_test  = x_test.values\n",
        "        self.y_train = y_train.values\n",
        "        self.y_test  = y_test.values\n",
        "\n",
        "           \n",
        "    def normalize(self): # zscore normalization\n",
        "           \n",
        "        sclr = StandardScaler()\n",
        "        self.nx_train = sclr.fit_transform(self.x_train)\n",
        "        self.nx_test  = sclr.transform(self.x_test)\n",
        "           \n",
        "    def normalize_mn(self): #Min max normalization (scale all features to range(0,1))\n",
        "        sclr = MinMaxScaler()\n",
        "        self.nnx_train = sclr.fit_transform(self.x_train)\n",
        "        self.nnx_test  = sclr.transform(self.x_test)\n",
        "              "
      ],
      "metadata": {
        "id": "S1NIoCHKhQFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Helper functions for:\n",
        "## 1- evaluating linear regression models via MSE and R2 score\n",
        "## 2- The gradient function used for gradient descent"
      ],
      "metadata": {
        "id": "6__Vyc46ZJRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions for:\n",
        "# 1- evaluating linear regression models via MSE and R2 score\n",
        "# 2- The gradient function used for gradient descent\n",
        "\n",
        "def reg_eval(y, y_pred):\n",
        "    mse = mean_squared_error(y, y_pred)\n",
        "    r2 = r2_score(y, y_pred)\n",
        "    print(f'MSE: {mse}')\n",
        "    print(f'R2 score: {r2}')\n",
        "    return mse, r2\n",
        "\n",
        "\n",
        "\n",
        "def gradient( x, y, w, alpha=0):\n",
        "    y_pred =  x @ w \n",
        "    dlt_y = y_pred - y\n",
        "    N, _ = x.shape\n",
        "\n",
        "    \n",
        "    grad = (.5*np.dot(dlt_y.T, x)/N) + alpha * w.T\n",
        "    # delta y is inversed to adjust the dimensions for multiplication\n",
        "    return grad.T # To convert into (D,1) Format\n",
        "\n"
      ],
      "metadata": {
        "id": "k6TOBy6PuCui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The bellow cell contains:\n",
        "### 1- The GradDescent class for performing gradient descent optimization\n",
        "### 2- The Linear Regression class that fits the data using least square and \n",
        "### gradient descent"
      ],
      "metadata": {
        "id": "ue4I07rYZSZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell contains:\n",
        "# 1- The GradDescent class for performing gradient descent optimization\n",
        "# 2- The Linear Regression class that fits the data using least square and \n",
        "# gradient descent\n",
        "\n",
        "class GradDescent:\n",
        "    \n",
        "    def __init__(self, learning_rate=.001, max_iters=1e4, epsilon=1e-8,\n",
        "                 btch_sz=32, tol=5, alpha=0.01, record_history=False):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_iters = max_iters\n",
        "        self.record_history = record_history\n",
        "        self.epsilon = epsilon\n",
        "        self.btch_sz = btch_sz # batch size\n",
        "        self.alpha = alpha # For L2 regularization\n",
        "        self.tol = tol # Tolerance\n",
        "        if record_history:\n",
        "            self.w_history = []                 #to store the weight history for visualization\n",
        "            \n",
        "    \n",
        "\n",
        "    def run(self, gradient_fn, x, y, w):        \n",
        "        \n",
        "        grad = np.inf\n",
        "        tol  = 0    #tolerance tracking index\n",
        "        btch = 0    #batch tracking index\n",
        "        N = x.shape[0]\n",
        "        btch_num = np.floor(N/self.btch_sz) # Number of full batches (e.g., a dataset\n",
        "        # with length of 10 and batch size of 3 will have 3 full batches)\n",
        "        \n",
        "        #--------- Initialize a list to store losses in each iteration\n",
        "        tmp_ls = []\n",
        "        #-----------\n",
        "        for ind in range(int(self.max_iters)):\n",
        "            if ind%100 == 0: # print iteration\n",
        "                print(f'Iteration: {ind}')\n",
        "                \n",
        "            if np.linalg.norm(grad) < self.epsilon: # If grad goes bellow the epsilon\n",
        "                if tol >= self.tol: # if the grad had small changes for tol iterations\n",
        "                    break\n",
        "                else:\n",
        "                    tol+=1\n",
        "            \n",
        "            if btch == 0:    # Batch initiation. if batch tracker is zero, get \n",
        "            # a shuffled index set to choose from x and y instances when each batch \n",
        "            # is being processes\n",
        "                tmp_ind = np.random.permutation(np.arange(N))\n",
        "            \n",
        "            if btch==btch_num: # for the last batch, most of the times its length\n",
        "            # is not equal to the batch size (is smaller), and this can cause problem\n",
        "            # if you use routine indexing\n",
        "                slc_ind = tmp_ind[(btch)*self.btch_sz:]\n",
        "                x_bt = x[slc_ind, :]\n",
        "                y_bt = y[slc_ind,:]\n",
        "\n",
        "                btch = 0 # Reset batch tracking index\n",
        "            else:\n",
        "                slc_ind = tmp_ind[(btch)*self.btch_sz:(btch+1)*self.btch_sz]\n",
        "                x_bt = x[slc_ind, :]\n",
        "                y_bt = y[slc_ind, :]\n",
        "\n",
        "                btch += 1\n",
        "            \n",
        "            grad = gradient_fn(x_bt, y_bt, w, self.alpha)  #Calculate gradient \n",
        "           \n",
        "            w = w - self.learning_rate * grad # Take the step\n",
        "            # ------------- calculate and store loss -----------\n",
        "            tmp_y = x @ w\n",
        "            tmp_ls.append(mean_squared_error(y, tmp_y)) #Store loss in each iteration\n",
        "            #----------------\n",
        "            if self.record_history:\n",
        "                self.w_history.append(w)\n",
        "                \n",
        "            if tol>0  and np.linalg.norm(grad) > self.epsilon: # reset tolerance if gradient goes over epsilon\n",
        "                tol=0 \n",
        "            \n",
        "        return w, tmp_ls\n",
        "       \n",
        "\n",
        "\n",
        "\n",
        "#%%\n",
        "\n",
        "\n",
        "\n",
        "class LinearReg:\n",
        "    '''\n",
        "    The linear regression class. The class  performes training and prediction with \n",
        "    least square and gradient discent. \n",
        "    \n",
        "    '''\n",
        "    \n",
        "    \n",
        "    def __init__(self, add_bias=True):\n",
        "        self.add_bias = add_bias\n",
        "        \n",
        "    def fit_ls(self, x, y):\n",
        "        if x.ndim == 1:\n",
        "            x = x[:, None]                         #add a dimension for the features\n",
        "        N = x.shape[0]\n",
        "        if self.add_bias:\n",
        "            x = np.column_stack([x,np.ones(N)])    #add bias by adding a constant feature of value 1\n",
        "        #alternatively: self.w = np.linalg.inv(x.T @ x)@x.T@y\n",
        "        self.w = np.linalg.lstsq(x, y)[0]          #return w for the least square difference\n",
        "        return self  \n",
        "    \n",
        "    \n",
        "    def predict_ls(self, x):     #least square predictinon\n",
        "        if self.add_bias:\n",
        "            N = x.shape[0]\n",
        "            x = np.column_stack([x,np.ones(N)])\n",
        "\n",
        "        y_pred = x @ self.w                             #predict the y values\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "\n",
        "    def fit_grd(self, x, y, optimizer, gradient):   #grad descent fitting\n",
        "        if x.ndim == 1:\n",
        "            x = x[:, None]                         #add a dimension for the features\n",
        "        N, _ = x.shape\n",
        "        if self.add_bias:\n",
        "            x = np.column_stack([x,np.ones(N)])\n",
        "        \n",
        "        _, D = x.shape\n",
        "        # w0 = np.zeros((D,1))\n",
        "        w0 = np.random.randn(D,1)    #Initialize weighs with random normal values\n",
        "        self.w_grd, self.tmp_ls = optimizer.run(gradient, x, y, w0 ) \n",
        "        \n",
        "      \n",
        "            \n",
        "    def predict_grd(self, x):   # gradient descent prediction\n",
        "        if self.add_bias:\n",
        "            N = x.shape[0]\n",
        "            x = np.column_stack([x,np.ones(N)])\n",
        "\n",
        "        y_pred = x @ self.w_grd                             #predict the y values\n",
        "        return y_pred"
      ],
      "metadata": {
        "id": "UXqeI5i2umsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The bellow cell will:\n",
        "Upload the data. \n",
        "Create the regression data class.\n",
        "Calculate and print statistical summries for variables. X6 and X8 seem to be categorical though a few others (like X5) also have few unique values"
      ],
      "metadata": {
        "id": "pmrfurZUZ9bE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Need to upload the data into colab first\n",
        "uploaded = files.upload()\n",
        "\n",
        "pth = '/ENB2012_data.xlsx' # Path to load the data\n",
        "rg_dat = reg_dat(pth) # The regression data instance\n",
        "rg_dat.stat_sum(prnt=True, save=False) #\n",
        "\n",
        "#\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "id": "3gf5sJY1wt9C",
        "outputId": "e003b6ba-cf07-4934-c2c0-8648450ff6b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e6460f4f-a1b8-4036-bee3-d711d29048f8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e6460f4f-a1b8-4036-bee3-d711d29048f8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ENB2012_data.xlsx to ENB2012_data.xlsx\n",
            "               X1          X2          X3          X4         X5          X6  \\\n",
            "count  768.000000  768.000000  768.000000  768.000000  768.00000  768.000000   \n",
            "mean     0.764167  671.708333  318.500000  176.604167    5.25000    3.500000   \n",
            "std      0.105777   88.086116   43.626481   45.165950    1.75114    1.118763   \n",
            "min      0.620000  514.500000  245.000000  110.250000    3.50000    2.000000   \n",
            "25%      0.682500  606.375000  294.000000  140.875000    3.50000    2.750000   \n",
            "50%      0.750000  673.750000  318.500000  183.750000    5.25000    3.500000   \n",
            "75%      0.830000  741.125000  343.000000  220.500000    7.00000    4.250000   \n",
            "max      0.980000  808.500000  416.500000  220.500000    7.00000    5.000000   \n",
            "\n",
            "               X7         X8          Y1          Y2  \n",
            "count  768.000000  768.00000  768.000000  768.000000  \n",
            "mean     0.234375    2.81250   22.307195   24.587760  \n",
            "std      0.133221    1.55096   10.090204    9.513306  \n",
            "min      0.000000    0.00000    6.010000   10.900000  \n",
            "25%      0.100000    1.75000   12.992500   15.620000  \n",
            "50%      0.250000    3.00000   18.950000   22.080000  \n",
            "75%      0.400000    4.00000   31.667500   33.132500  \n",
            "max      0.400000    5.00000   43.100000   48.030000  \n",
            "Categorical data:\n",
            "           X8    X6         X4    X5     X7\n",
            "0.00     6.25   NaN        NaN   NaN   6.25\n",
            "0.10      NaN   NaN        NaN   NaN  31.25\n",
            "0.25      NaN   NaN        NaN   NaN  31.25\n",
            "0.40      NaN   NaN        NaN   NaN  31.25\n",
            "1.00    18.75   NaN        NaN   NaN    NaN\n",
            "2.00    18.75  25.0        NaN   NaN    NaN\n",
            "3.00    18.75  25.0        NaN   NaN    NaN\n",
            "3.50      NaN   NaN        NaN  50.0    NaN\n",
            "4.00    18.75  25.0        NaN   NaN    NaN\n",
            "5.00    18.75  25.0        NaN   NaN    NaN\n",
            "7.00      NaN   NaN        NaN  50.0    NaN\n",
            "110.25    NaN   NaN   8.333333   NaN    NaN\n",
            "122.50    NaN   NaN  16.666667   NaN    NaN\n",
            "147.00    NaN   NaN  25.000000   NaN    NaN\n",
            "220.50    NaN   NaN  50.000000   NaN    NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split into train test with a ratio of 0.2. Outcome can be 9 (Y2) or 8 (Y1)\n",
        "rg_dat.split(tst_ratio=0.2, outcm=8, rnd_stat=100) #Split into train test with a ratio of 0.2\n",
        "rg_dat.normalize() # zscore normalize the data\n"
      ],
      "metadata": {
        "id": "n3eJfEtccRQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linrg = LinearReg() #Create linear regression instance\n",
        "linrg.fit_ls(rg_dat.nx_train, rg_dat.y_train) #fit least square (dat.nx_train is  z score normalized data)\n",
        "\n",
        "y_prd = linrg.predict_ls(rg_dat.nx_test) # predict using least square coefs\n",
        "y_prd_tr = linrg.predict_ls(rg_dat.nx_train)\n",
        "\n",
        "reg_eval(rg_dat.y_test, y_prd) #test set evaluation\n",
        "\n",
        "reg_eval(rg_dat.y_train, y_prd_tr) #training set evaluation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJypCyvof2La",
        "outputId": "f358e9f4-78ae-4906-a1db-25def4c8acb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 8.441431556980932\n",
            "R2 score: 0.9094940323320938\n",
            "MSE: 8.55119792801829\n",
            "R2 score: 0.917609840188006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-c904f89bf584>:104: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  self.w = np.linalg.lstsq(x, y)[0]          #return w for the least square difference\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.55119792801829, 0.917609840188006)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optmz = GradDescent(learning_rate=.005, max_iters=1e5, epsilon=1e-4,\n",
        "             btch_sz=128, alpha=0, tol=5) # Optimizer. Alpha tunes L2 regularization power\n",
        "\n",
        "\n",
        "linrg.fit_grd(rg_dat.nx_train, rg_dat.y_train[:, None], optmz, gradient) #Fit\n"
      ],
      "metadata": {
        "id": "ua_Ibf4OgNKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = linrg.predict_grd(rg_dat.nx_test)# Predict\n",
        "reg_eval(rg_dat.y_test, y_pred) #test set evaluation\n",
        "\n",
        "y_prd_tr = linrg.predict_grd(rg_dat.nx_train)\n",
        "reg_eval(rg_dat.y_train, y_prd_tr) #train set evaluation\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzwmRSgag2mh",
        "outputId": "fe74b00b-dd91-456f-fcec-fde104652429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 8.512514887106677\n",
            "R2 score: 0.9087319026465468\n",
            "MSE: 8.57618675039632\n",
            "R2 score: 0.9173690747319178\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.57618675039632, 0.9173690747319178)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}